
@report{burrows_block-sorting_1994,
	title = {A block-sorting lossless data compression algorithm},
	author = {Burrows, M. and Wheeler, D. J.},
	date = {1994},
	keywords = {notion},
	file = {Burrows and Wheeler - 1994 - A block-sorting lossless data compression algorith.pdf:/home/skadic/Zotero/storage/UTKN8MUV/Burrows and Wheeler - 1994 - A block-sorting lossless data compression algorith.pdf:application/pdf;Citeseer - Snapshot:/home/skadic/Zotero/storage/22NA9X4T/summary.html:text/html},
}

@article{ziv_universal_1977,
	title = {A universal algorithm for sequential data compression},
	volume = {23},
	issn = {0018-9448},
	doi = {10.1109/TIT.1977.1055714},
	pages = {337--343},
	number = {3},
	journaltitle = {{IEEE} Transactions on Information Theory},
	shortjournal = {{IEEE} Trans. Inform. Theory},
	author = {Ziv, J. and Lempel, A.},
	date = {1977},
	langid = {english},
	keywords = {notion},
	file = {Ziv and Lempel - 1977 - A universal algorithm for sequential data compress.pdf:/home/skadic/Zotero/storage/99KG6KHH/Ziv and Lempel - 1977 - A universal algorithm for sequential data compress.pdf:application/pdf},
}

@article{huffman_method_1952,
	title = {A Method for the Construction of Minimum-Redundancy Codes},
	volume = {40},
	issn = {0096-8390},
	doi = {10.1109/JRPROC.1952.273898},
	pages = {1098--1101},
	number = {9},
	journaltitle = {Proceedings of the {IRE}},
	shortjournal = {Proc. {IRE}},
	author = {Huffman, David},
	date = {1952},
	keywords = {notion},
	file = {Huffman - 1952 - A Method for the Construction of Minimum-Redundanc.pdf:/home/skadic/Zotero/storage/RP4ZY7PK/Huffman - 1952 - A Method for the Construction of Minimum-Redundanc.pdf:application/pdf},
}

@article{belazzougui_block_2021,
	title = {Block trees},
	volume = {117},
	issn = {0022-0000},
	doi = {10.1016/j.jcss.2020.11.002},
	abstract = {Let string S[1..n] be parsed into z phrases by the Lempel-Ziv algorithm. The corresponding compression algorithm encodes S in O(z) space, but it does not support random access to S. We introduce a data structure, the block tree, that represents S in O(zlog⁡(n/z)) space and extracts any symbol of S in time O(log⁡(n/z)), among other space-time tradeoffs. The structure also supports other queries that are useful for building compressed data structures on top of S. Further, block trees can be built in linear time and in a scalable manner. Our experiments show that block trees offer relevant space-time tradeoffs compared to other compressed string representations for highly repetitive strings.},
	pages = {1--22},
	journaltitle = {Journal of Computer and System Sciences},
	shortjournal = {Journal of Computer and System Sciences},
	author = {Belazzougui, Djamal and Cáceres, Manuel and Gagie, Travis and Gawrychowski, Paweł and Kärkkäinen, Juha and Navarro, Gonzalo and Ordóñez, Alberto and Puglisi, Simon J. and Tabei, Yasuo},
	date = {2021},
	langid = {english},
	keywords = {\_read, Compressed data structures, Lempel-Ziv compression, Repetitive string collections, notion},
	file = {Belazzougui et al. - 2021 - Block trees.pdf:/home/skadic/Zotero/storage/TIKV85FT/Belazzougui et al. - 2021 - Block trees.pdf:application/pdf;ScienceDirect Snapshot:/home/skadic/Zotero/storage/5GM85RU9/S0022000020301033.html:text/html},
}

@article{dinklage_practical_2021,
	title = {Practical Wavelet Tree Construction},
	volume = {26},
	issn = {1084-6654},
	doi = {10.1145/3457197},
	abstract = {We present new sequential and parallel algorithms for wavelet tree construction based on a new bottom-up technique. This technique makes use of the structure of the wavelet trees—refining the characters represented in a node of the tree with increasing depth—in an opposite way, by first computing the leaves (most refined), and then propagating this information upwards to the root of the tree. We first describe new sequential algorithms, both in {RAM} and external memory. Based on these results, we adapt these algorithms to parallel computers, where we address both shared memory and distributed memory settings. In practice, all our algorithms outperform previous ones in both time and memory efficiency, because we can compute all auxiliary information solely based on the information we obtained from computing the leaves. Most of our algorithms are also adapted to the wavelet matrix, a variant that is particularly suited for large alphabets.},
	pages = {1.8:1--1.8:67},
	journaltitle = {{ACM} Journal of Experimental Algorithmics},
	shortjournal = {{ACM} J. Exp. Algorithmics},
	author = {Dinklage, Patrick and Ellert, Jonas and Fischer, Johannes and Kurpicz, Florian and Löbel, Marvin},
	urldate = {2023-02-16},
	date = {2021},
	keywords = {Data structures, distributed memory, external memory, shared memory, text indexing, notion},
	file = {Full Text PDF:/home/skadic/Zotero/storage/65GQZNDF/Dinklage et al. - 2021 - Practical Wavelet Tree Construction.pdf:application/pdf},
}

@misc{gagie_approximating_2015,
	title = {Approximating {LZ}77 in Small Space},
	doi = {10.48550/arXiv.1503.02416},
	number = {{arXiv}:1503.02416},
	publisher = {{arXiv}},
	author = {Gagie, Travis},
	date = {2015},
	keywords = {Computer Science - Data Structures and Algorithms, notion},
	file = {arXiv.org Snapshot:/home/skadic/Zotero/storage/VNQYAIIC/1503.html:text/html;Gagie - 2015 - Approximating LZ77 in Small Space.pdf:/home/skadic/Zotero/storage/XTWSB8I7/Gagie - 2015 - Approximating LZ77 in Small Space.pdf:application/pdf},
}

@inproceedings{bille_lempel-ziv_2017,
	location = {Dagstuhl, Germany},
	title = {Lempel-Ziv Compression in a Sliding Window},
	isbn = {978-3-95977-039-2},
	doi = {10.4230/LIPIcs.CPM.2017.15},
	publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
	author = {Bille, Philip and Cording, Patrick Hagge and Fischer, Johannes and Gørtz, Inge Li},
	editor = {Kärkkäinen, Juha and Radoszewski, Jakub and Rytter, Wojciech},
	date = {2017},
	note = {{ISSN}: 1868-8969},
	keywords = {\_read, Lempel-Ziv parsing, notion, rightmost matching, sliding window},
	file = {Bille et al. - 2017 - Lempel-Ziv Compression in a Sliding Window.pdf:/home/skadic/Zotero/storage/9CV99KEJ/Bille et al. - 2017 - Lempel-Ziv Compression in a Sliding Window.pdf:application/pdf;Snapshot:/home/skadic/Zotero/storage/9EGAFMX7/7331.html:text/html},
}

@inproceedings{crochemore_lpf_2009,
	location = {Berlin, Heidelberg},
	title = {{LPF} Computation Revisited},
	isbn = {978-3-642-10217-2},
	doi = {10.1007/978-3-642-10217-2_18},
	series = {Lecture Notes in Computer Science},
	abstract = {We present efficient algorithms for storing past segments of a text. They are computed using two previously computed read-only arrays ({SUF} and {LCP}) composing the Suffix Array of the text. They compute the maximal length of the previous factor (subword) occurring at each position of the text in a table called {LPF}. This notion is central both in many conservative text compression techniques and in the most efficient algorithms for detecting motifs and repetitions occurring in a text.},
	pages = {158--169},
	booktitle = {Combinatorial Algorithms},
	publisher = {Springer},
	author = {Crochemore, Maxime and Ilie, Lucian and Iliopoulos, Costas S. and Kubica, Marcin and Rytter, Wojciech and Waleń, Tomasz},
	editor = {Fiala, Jiří and Kratochvíl, Jan and Miller, Mirka},
	date = {2009},
	langid = {english},
	keywords = {detection of repetitions, longest previous factor, suffix array, text compression, Ziv-Lempel factorisation, notion},
	file = {Crochemore et al. - 2009 - LPF Computation Revisited.pdf:/home/skadic/Zotero/storage/96ALII46/Crochemore et al. - 2009 - LPF Computation Revisited.pdf:application/pdf},
}

@article{kreft_lz77-like_2010,
	title = {{LZ}77-Like Compression with Fast Random Access},
	doi = {10.1109/DCC.2010.29},
	pages = {239--248},
	journaltitle = {2010 Data Compression Conference},
	author = {Kreft, Sebastian and Navarro, Gonzalo},
	date = {2010},
	keywords = {notion},
	file = {Kreft and Navarro - 2010 - LZ77-Like Compression with Fast Random Access.pdf:/home/skadic/Zotero/storage/4GHXSCIK/Kreft and Navarro - 2010 - LZ77-Like Compression with Fast Random Access.pdf:application/pdf},
}

@inproceedings{grossi_high-order_2003,
	location = {{USA}},
	title = {High-Order Entropy-Compressed Text Indexes},
	isbn = {0-89871-538-5},
	doi = {10.5555/644108.644250},
	series = {{SODA} '03},
	abstract = {We present a novel implementation of compressed suffix arrays exhibiting new tradeoffs between search time and space occupancy for a given text (or sequence) of n symbols over an alphabet σ, where each symbol is encoded by lg{\textbar}σ{\textbar} bits. We show that compressed suffix arrays use just {nHh} + σ bits, while retaining full text indexing functionalities, such as searching any pattern sequence of length m in O(m lg {\textbar}σ{\textbar} + polylog(n)) time. The term Hh ≤ lg {\textbar}σ{\textbar} denotes the hth-order empirical entropy of the text, which means that our index is nearly optimal in space apart from lower-order terms, achieving asymptotically the empirical entropy of the text (with a multiplicative constant 1). If the text is highly compressible so that Hn = o(1) and the alphabet size is small, we obtain a text index with o(m) search time that requires only o(n) bits. Further results and tradeoffs are reported in the paper.},
	booktitle = {Proceedings of the Fourteenth Annual {ACM}-{SIAM} Symposium on Discrete Algorithms},
	publisher = {Society for Industrial and Applied Mathematics},
	author = {Grossi, Roberto and Gupta, Ankur and Vitter, Jeffrey Scott},
	date = {2003},
	note = {event-place: Baltimore, Maryland},
	keywords = {notion},
	file = {Grossi et al. - 2003 - High-Order Entropy-Compressed Text Indexes.pdf:/home/skadic/Zotero/storage/2I22R5FX/Grossi et al. - 2003 - High-Order Entropy-Compressed Text Indexes.pdf:application/pdf},
}

@article{gagie_optimal-time_2018,
	title = {Optimal-Time Text Indexing in {BWT}-runs Bounded Space},
	doi = {10.1137/1.9781611975031.96},
	author = {Gagie, Travis and Navarro, Gonzalo and Prezza, Nicola},
	date = {2018},
	doi = {10.1137/1.9781611975031.96},
	note = {\_eprint: https://epubs.siam.org/doi/pdf/10.1137/1.9781611975031.96},
	keywords = {notion},
	file = {Gagie et al. - Optimal-Time Text Indexing in BWT-runs Bounded Spa.pdf:/home/skadic/Zotero/storage/XZK4YYPY/Gagie et al. - Optimal-Time Text Indexing in BWT-runs Bounded Spa.pdf:application/pdf},
}

@inproceedings{p_ferragina_opportunistic_2000,
	title = {Opportunistic data structures with applications},
	isbn = {0272-5428},
	doi = {10.1109/SFCS.2000.892127},
	abstract = {We address the issue of compressing and indexing data. We devise a data structure whose space occupancy is a function of the entropy of the underlying data set. We call the data structure opportunistic since its space occupancy is decreased when the input is compressible and this space reduction is achieved at no significant slowdown in the query performance. More precisely, its space occupancy is optimal in an information-content sense because text T[1,u] is stored using O(H/sub k/(T))+o(1) bits per input symbol in the worst case, where H/sub k/(T) is the kth order empirical entropy of T (the bound holds for any fixed k). Given an arbitrary string P[1,p], the opportunistic data structure allows to search for the occurrences of P in T in O(p+occlog/sup /spl epsiv//u) time (for any fixed /spl epsiv/{\textgreater}0). If data are uncompressible we achieve the best space bound currently known (Grossi and Vitter, 2000); on compressible data our solution improves the succinct suffix array of (Grossi and Vitter, 2000) and the classical suffix tree and suffix array data structures either in space or in query time or both. We also study our opportunistic data structure in a dynamic setting and devise a variant achieving effective search and update time bounds. Finally, we show how to plug our opportunistic data structure into the Glimpse tool (Manber and Wu, 1994). The result is an indexing tool which achieves sublinear space and sublinear query time complexity.},
	eventtitle = {Proceedings 41st Annual Symposium on Foundations of Computer Science},
	pages = {390--398},
	booktitle = {Proceedings 41st Annual Symposium on Foundations of Computer Science},
	author = {{P. Ferragina} and {G. Manzini}},
	date = {2000},
	note = {Journal Abbreviation: Proceedings 41st Annual Symposium on Foundations of Computer Science},
	keywords = {notion},
	file = {P. Ferragina and G. Manzini - 2000 - Opportunistic data structures with applications.pdf:/home/skadic/Zotero/storage/98Y4GHV5/P. Ferragina and G. Manzini - 2000 - Opportunistic data structures with applications.pdf:application/pdf},
}

@article{vyverman_prospects_2012,
	title = {Prospects and limitations of full-text index structures in genome analysis},
	volume = {40},
	issn = {0305-1048},
	doi = {10.1093/nar/gks408},
	abstract = {The combination of incessant advances in sequencing technology producing large amounts of data and innovative bioinformatics approaches, designed to cope with this data flood, has led to new interesting results in the life sciences. Given the magnitude of sequence data to be processed, many bioinformatics tools rely on efficient solutions to a variety of complex string problems. These solutions include fast heuristic algorithms and advanced data structures, generally referred to as index structures. Although the importance of index structures is generally known to the bioinformatics community, the design and potency of these data structures, as well as their properties and limitations, are less understood. Moreover, the last decade has seen a boom in the number of variant index structures featuring complex and diverse memory-time trade-offs. This article brings a comprehensive state-of-the-art overview of the most popular index structures and their recently developed variants. Their features, interrelationships, the trade-offs they impose, but also their practical limitations, are explained and compared.},
	pages = {6993--7015},
	number = {15},
	journaltitle = {Nucleic Acids Research},
	shortjournal = {Nucleic Acids Research},
	author = {Vyverman, Michaël and De Baets, Bernard and Fack, Veerle and Dawyndt, Peter},
	date = {2012},
	keywords = {notion},
	file = {Vyverman et al. - 2012 - Prospects and limitations of full-text index struc.pdf:/home/skadic/Zotero/storage/TGNEEEPB/Vyverman et al. - 2012 - Prospects and limitations of full-text index struc.pdf:application/pdf},
}

@article{meyer_giant_2021,
	title = {Giant lungfish genome elucidates the conquest of land by vertebrates},
	volume = {590},
	issn = {1476-4687},
	doi = {10.1038/s41586-021-03198-8},
	abstract = {Lungfishes belong to lobe-fined fish (Sarcopterygii) that, in the Devonian period, ‘conquered’ the land and ultimately gave rise to all land vertebrates, including humans1–3. Here we determine the chromosome-quality genome of the Australian lungfish (Neoceratodus forsteri), which is known to have the largest genome of any animal. The vast size of this genome, which is about 14× larger than that of humans, is attributable mostly to huge intergenic regions and introns with high repeat content (around 90\%), the components of which resemble those of tetrapods (comprising mainly long interspersed nuclear elements) more than they do those of ray-finned fish. The lungfish genome continues to expand independently (its transposable elements are still active), through mechanisms different to those of the enormous genomes of salamanders. The 17 fully assembled lungfish macrochromosomes maintain synteny to other vertebrate chromosomes, and all microchromosomes maintain conserved ancient homology with the ancestral vertebrate karyotype. Our phylogenomic analyses confirm previous reports that lungfish occupy a key evolutionary position as the closest living relatives to tetrapods4,5, underscoring the importance of lungfish for understanding innovations associated with terrestrialization. Lungfish preadaptations to living on land include the gain of limb-like expression in developmental genes such as hoxc13 and sall1 in their lobed fins. Increased rates of evolution and the duplication of genes associated with obligate air-breathing, such as lung surfactants and the expansion of odorant receptor gene families (which encode proteins involved in detecting airborne odours), contribute to the tetrapod-like biology of lungfishes. These findings advance our understanding of this major transition during vertebrate evolution.},
	pages = {284--289},
	number = {7845},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Meyer, Axel and Schloissnig, Siegfried and Franchini, Paolo and Du, Kang and Woltering, Joost M. and Irisarri, Iker and Wong, Wai Yee and Nowoshilow, Sergej and Kneitz, Susanne and Kawaguchi, Akane and Fabrizius, Andrej and Xiong, Peiwen and Dechaud, Corentin and Spaink, Herman P. and Volff, Jean-Nicolas and Simakov, Oleg and Burmester, Thorsten and Tanaka, Elly M. and Schartl, Manfred},
	date = {2021},
	file = {Full Text:/home/skadic/Zotero/storage/7PTCHXLE/Meyer et al. - 2021 - Giant lungfish genome elucidates the conquest of l.pdf:application/pdf},
}

@article{sanger_nucleotide_1977,
	title = {Nucleotide sequence of bacteriophage φX174 {DNA}},
	volume = {265},
	rights = {1977 Nature Publishing Group},
	issn = {1476-4687},
	doi = {10.1038/265687a0},
	abstract = {A {DNA} sequence for the genome of bacteriophage φX174 of approximately 5,375 nucleotides has been determined using the rapid and simple ‘plus and minus’ method. The sequence identifies many of the features responsible for the production of the proteins of the nine known genes of the organism, including initiation and termination sites for the proteins and {RNAs}. Two pairs of genes are coded by the same region of {DNA} using different reading frames.},
	pages = {687--695},
	number = {5596},
	journaltitle = {Nature},
	author = {Sanger, F. and Air, G. M. and Barrell, B. G. and Brown, N. L. and Coulson, A. R. and Fiddes, J. C. and Hutchison, C. A. and Slocombe, P. M. and Smith, M.},
	date = {1977},
	langid = {english},
	note = {Number: 5596
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
	file = {Full Text PDF:/home/skadic/Zotero/storage/S9U2WUEK/Sanger et al. - 1977 - Nucleotide sequence of bacteriophage φX174 DNA.pdf:application/pdf},
}

@article{fiers_complete_1976,
	title = {Complete nucleotide sequence of bacteriophage {MS}2 {RNA}: primary and secondary structure of the replicase gene},
	volume = {260},
	rights = {1976 Nature Publishing Group},
	issn = {1476-4687},
	doi = {10.1038/260500a0},
	shorttitle = {Complete nucleotide sequence of bacteriophage {MS}2 {RNA}},
	abstract = {Bacteriophage {MS}2 {RNA} is 3,569 nucleotides long. The nucleotide sequence has been established for the third and last gene, which codes for the replicase protein. A secondary structure model has also been proposed. Biological properties, such as ribosome binding and codon interactions can now be discussed on a molecular basis. As the sequences for the other regions of this {RNA} have been published already, the complete, primary chemical structure of a viral genome has now been established.},
	pages = {500--507},
	number = {5551},
	journaltitle = {Nature},
	author = {Fiers, W. and Contreras, R. and Duerinck, F. and Haegeman, G. and Iserentant, D. and Merregaert, J. and Min Jou, W. and Molemans, F. and Raeymaekers, A. and Van den Berghe, A. and Volckaert, G. and Ysebaert, M.},
	date = {1976},
	langid = {english},
	note = {Number: 5551
Publisher: Nature Publishing Group},
	keywords = {Humanities and Social Sciences, multidisciplinary, Science},
	file = {Full Text PDF:/home/skadic/Zotero/storage/M4KMUKFR/Fiers et al. - 1976 - Complete nucleotide sequence of bacteriophage MS2 .pdf:application/pdf},
}

@misc{belazzougui_queries_2014,
	title = {Queries on {LZ}-Bounded Encodings},
	doi = {10.48550/arXiv.1412.0967},
	abstract = {We describe a data structure that stores a string \$S\$ in space similar to that of its Lempel-Ziv encoding and efficiently supports access, rank and select queries. These queries are fundamental for implementing succinct and compressed data structures, such as compressed trees and graphs. We show that our data structure can be built in a scalable manner and is both small and fast in practice compared to other data structures supporting such queries.},
	number = {{arXiv}:1412.0967},
	publisher = {{arXiv}},
	author = {Belazzougui, Djamal and Gagie, Travis and Gawrychowski, Paweł and Kärkkäinen, Juha and Ordóñez, Alberto and Puglisi, Simon J. and Tabei, Yasuo},
	date = {2014},
	eprinttype = {arxiv},
	eprint = {1412.0967 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms, notion},
	file = {arXiv.org Snapshot:/home/skadic/Zotero/storage/LGZ6I6LB/1412.html:text/html;Belazzougui et al. - 2014 - Queries on LZ-Bounded Encodings.pdf:/home/skadic/Zotero/storage/49EEZ3IV/Belazzougui et al. - 2014 - Queries on LZ-Bounded Encodings.pdf:application/pdf},
}

@thesis{caceres_compressed_2019,
	location = {Santiago, Chile},
	title = {Compressed Suffix Trees for Repetitive Collections Based on Block Trees},
	url = {https://users.dcc.uchile.cl/~gnavarro/mem/algoritmos/tesisManuel.pdf},
	abstract = {The Block Tree is a recently proposed data structure representing a sequence T of length
n in space bounded by the number of phrases z of the Lempel-Ziv parsing of T . It uses
O(z log(n/z)) space and supports access to symbols and other operations in logarithmic
time.
We contribute both to the theoretical and practical development of Block Trees, proving
new properties, presenting the first implementation faithful to its theoretical description,
making further improvements to the structure, and studying a wide set of variants.},
	pagetotal = {103},
	institution = {University of Chile},
	type = {Master Thesis},
	author = {Cáceres, Manuel},
	urldate = {2023-04-27},
	date = {2019},
	langid = {english},
	keywords = {notion},
	file = {Cáceres - 2019 - Compressed Suffix Trees for Repetitive Collections.pdf:/home/skadic/Zotero/storage/49PRGUVE/Cáceres - 2019 - Compressed Suffix Trees for Repetitive Collections.pdf:application/pdf},
}

@inproceedings{ferragina_repetition-_2021,
	title = {Repetition- and linearity-aware rank/select dictionaries},
	doi = {10.4230/LIPIcs.ISAAC.2021.64},
	pages = {64:1--64:16},
	booktitle = {Proceedings of the 32nd International Symposium on Algorithms and Computation ({ISAAC})},
	author = {Ferragina, Paolo and Manzini, Giovanni and Vinciguerra, Giorgio},
	date = {2021},
	keywords = {notion},
	file = {Ferragina et al. - 2021 - Repetition- and linearity-aware rankselect dictio.pdf:/home/skadic/Zotero/storage/2KEY2EJK/Ferragina et al. - 2021 - Repetition- and linearity-aware rankselect dictio.pdf:application/pdf},
}

@inproceedings{shun_practical_2013,
	title = {Practical Parallel Lempel-Ziv Factorization},
	doi = {10.1109/DCC.2013.20},
	pages = {123--132},
	booktitle = {2013 Data Compression Conference},
	author = {Shun, Julian and Zhao, Fuyao},
	date = {2013},
	keywords = {\_interesting, notion},
	file = {Shun and Zhao - 2013 - Practical Parallel Lempel-Ziv Factorization.pdf:/home/skadic/Zotero/storage/G8AQHG9M/Shun and Zhao - 2013 - Practical Parallel Lempel-Ziv Factorization.pdf:application/pdf},
}

@article{ferreira_time_2009,
	title = {Time and Memory Efficient Lempel-Ziv Compression Using Suffix Arrays},
	volume = {abs/0912.5449},
	doi = {10.48550/arXiv.0912.5449},
	journaltitle = {{CoRR}},
	author = {Ferreira, Artur J. and Oliveira, Arlindo L. and Figueiredo, Mário A. T.},
	date = {2009},
	keywords = {notion},
	file = {Ferreira et al. - 2009 - Time and Memory Efficient Lempel-Ziv Compression U.pdf:/home/skadic/Zotero/storage/UDTLNHR7/Ferreira et al. - 2009 - Time and Memory Efficient Lempel-Ziv Compression U.pdf:application/pdf},
}

@article{han_succinct_2022,
	title = {Succinct parallel Lempel–Ziv factorization on a multicore computer},
	volume = {78},
	doi = {10.1007/s11227-021-04165-w},
	abstract = {This article proposes a succinct parallel algorithm, called {pLZone}, to compute the Lempel–Ziv ({LZ}77) factorization of a size-n input string over a constant alphabet in \$\$\{{\textbackslash}mathcal \{O\}\}(n)\$\$time using approximately a small n-word workspace, where each word occupies \$\${\textbackslash}lceil {\textbackslash}mathrm\{log\}n{\textbackslash}rceil\$\$bits. {pLZone} is designed by dividing the computing process of the sequential factorization algorithm {LZone} into multiple stages that are organized as a pipeline to perform operations in parallel for acceleration, and a checking method is integrated into the pipeline to efficiently verify the output to prevent bugs during implementation. A performance evaluation experiment is conducted by running {pLZone} and the existing representative algorithms on a set of realistic and artificial datasets. Both the best time and space results are achieved by our proposed algorithm, which suggests that this work could provide a potential solution for efficient {LZ}77 computation.},
	number = {5},
	journaltitle = {The Journal of Supercomputing},
	shortjournal = {The Journal of Supercomputing},
	author = {Han, Ling Bo and Lao, Bin and Nong, Ge},
	date = {2022},
	keywords = {notion},
	file = {Han et al. - 2022 - Succinct parallel Lempel–Ziv factorization on a mu.pdf:/home/skadic/Zotero/storage/KVW9HJ9R/Han et al. - 2022 - Succinct parallel Lempel–Ziv factorization on a mu.pdf:application/pdf},
}

@article{blelloch_parallel_1996,
	title = {Parallel algorithms},
	volume = {28},
	doi = {10.5555/1882723.1882748},
	pages = {51--54},
	number = {1},
	author = {Blelloch, Guy E and Maggs, Bruce M},
	date = {1996},
	note = {Publisher: {ACM} New York, {NY}, {USA}},
	keywords = {notion},
	file = {Blelloch and Maggs - 1996 - Parallel algorithms.pdf:/home/skadic/Zotero/storage/HPAXGDSW/Blelloch and Maggs - 1996 - Parallel algorithms.pdf:application/pdf},
}

@book{jaja_introduction_1992,
	title = {An introduction to parallel algorithms},
	isbn = {978-0-201-54856-3},
	publisher = {Addison Wesley Longman Publishing Co., Inc.},
	author = {{JáJá}, Joseph},
	date = {1992},
	langid = {english},
	keywords = {\_read, notion},
	file = {JáJá - 1992 - An introduction to parallel algorithms.pdf:/home/skadic/Zotero/storage/85TRRQE6/JáJá - 1992 - An introduction to parallel algorithms.pdf:application/pdf},
}

@article{caceres_faster_2022,
	title = {Faster repetition-aware compressed suffix trees based on Block Trees},
	volume = {285},
	issn = {0890-5401},
	doi = {10.1016/j.ic.2021.104749},
	abstract = {The suffix tree is a fundamental data structure in stringology, but its space usage, though linear, is an important problem in applications like Bioinformatics. We design and implement a new compressed suffix tree ({CST}) targeted to highly repetitive texts, such as large genomic collections of the same species. Our first contribution is to enhance the Block Tree, a data structure that captures the repetitiveness of its input sequence, to represent the topology of trees with large repeated subtrees. Our so-called Block-Tree Compressed Topology ({BT}-{CT}) data structure augments the Block Tree nodes with data that speeds up tree navigation. Our Block-Tree {CST} ({BT}-{CST}), in turn, uses the {BT}-{CT} to compress the topology of the suffix tree, and also replaces the sampling of the suffix array and its inverse with grammar- and/or Block-Tree-based representations of those arrays. Our experimental results show that {BT}-{CTs} reach navigation speeds comparable to compact tree representations that are insensitive to repetitiveness, while using 2–10 times less space on the topologies of the suffix trees of repetitive collections. Our {BT}-{CST} is slightly larger than previous repetition-aware suffix trees based on grammar-compressed topologies, but outperforms them in time, often by orders of magnitude.},
	pages = {104749},
	journaltitle = {Information and Computation},
	shortjournal = {Information and Computation},
	author = {Cáceres, Manuel and Navarro, Gonzalo},
	date = {2022},
	keywords = {notion},
	file = {Cáceres and Navarro - 2022 - Faster repetition-aware compressed suffix trees ba.pdf:/home/skadic/Zotero/storage/3PB3VNFU/Cáceres and Navarro - 2022 - Faster repetition-aware compressed suffix trees ba.pdf:application/pdf},
}

@misc{rabin_fingerprinting_1981,
	title = {Fingerprinting by Random Polynomials},
	rights = {Center for Research in Computing Technology, Harvard University},
	author = {Rabin, Michael O.},
	date = {1981},
	keywords = {notion},
}

@inproceedings{moeini_parallel_2019,
	location = {Tehran, Iran},
	title = {Parallel Rabin-Karp Algorithm for String Matching using {GPU}},
	abstract = {String matching algorithms play an important role in
many aspects. In this paper, a new method is proposed for parallel
execution of Rabin-Karp string matching algorithm. In the
proposed method, all patterns are divided into different groups.
This categorization has been used to prevent redundant
comparisons and accelerate the matching process. This procedure
takes two advantages: a reduction in the number of comparisons
of hash values and a decline in the number of pattern reading from
global memory. It is recommended to implement the algorithm in
various cases on {NVIDIA} {GPUs} using {CUDA} Platform to
demonstrate the efficiency of the proposed algorithm.
Experimental results depict that the execution time of the
algorithm has decreased significantly. In the best case, the
proposed method is approximately 27 times faster than the series
mode.},
	eventtitle = {10th International Conference on Information and Knowledge Technology ({IKT} 2019)},
	author = {Moeini, Masoumeh and Shahhoseini, Hadi Shahriar},
	date = {2019},
	keywords = {notion},
	file = {Moeini and Shahhoseini - 2019 - Parallel Rabin-Karp Algorithm for String Matching .pdf:/home/skadic/Zotero/storage/CGZPAQ7B/Moeini and Shahhoseini - 2019 - Parallel Rabin-Karp Algorithm for String Matching .pdf:application/pdf},
}

@inproceedings{shah_improved_2018,
	location = {Cham},
	title = {Improved Parallel Rabin-Karp Algorithm Using Compute Unified Device Architecture},
	isbn = {978-3-319-63645-0},
	doi = {10.48550/arXiv.1810.01051},
	abstract = {String matching algorithms are among one of the most widely used algorithms in computer science. Traditional string matching algorithms are not enough for processing recent growth of data. Increasing efficiency of underlaying string matching algorithm will greatly increase the efficiency of any application. In recent years, Graphics processing units are emerged as highly parallel processor. They out perform best of the central processing units in scientific computation power. By combining recent advancement in graphics processing units with string matching algorithms will allows to speed up process of string matching. In this paper we proposed modified parallel version of Rabin-Karp algorithm using graphics processing unit. Based on that, result of {CPU} as well as parallel {GPU} implementations are compared for evaluating effect of varying number of threads, cores, file size as well as pattern size.},
	pages = {236--244},
	booktitle = {Information and Communication Technology for Intelligent Systems ({ICTIS} 2017) - Volume 2},
	publisher = {Springer International Publishing},
	author = {Shah, Parth and Oza, Rachana},
	editor = {Satapathy, Suresh Chandra and Joshi, Amit},
	date = {2018},
	keywords = {notion},
	file = {Shah and Oza - 2018 - Improved Parallel Rabin-Karp Algorithm Using Compu.pdf:/home/skadic/Zotero/storage/KR99VZ64/Shah and Oza - 2018 - Improved Parallel Rabin-Karp Algorithm Using Compu.pdf:application/pdf},
}

@article{maier_concurrent_2019,
	title = {Concurrent Hash Tables: Fast and General(?)!},
	volume = {5},
	issn = {2329-4949},
	doi = {10.1145/3309206},
	abstract = {Concurrent hash tables are one of the most important concurrent data structures, which are used in numerous applications. For some applications, it is common that hash table accesses dominate the execution time. To efficiently solve these problems in parallel, we need implementations that achieve speedups in highly concurrent scenarios. Unfortunately, currently available concurrent hashing libraries are far away from this requirement, in particular, when adaptively sized tables are necessary or contention on some elements occurs.Our starting point for better performing data structures is a fast and simple lock-free concurrent hash table based on linear probing that is, however, limited to word-sized key-value types and does not support dynamic size adaptation. We explain how to lift these limitations in a provably scalable way and demonstrate that dynamic growing has a performance overhead comparable to the same generalization in sequential hash tables.We perform extensive experiments comparing the performance of our implementations with six of the most widely used concurrent hash tables. Ours are considerably faster than the best algorithms with similar restrictions and an order of magnitude faster than the best more general tables. In some extreme cases, the difference even approaches four orders of magnitude.All our implementations discussed in this publication can be found on github [17].},
	number = {4},
	journaltitle = {{ACM} Trans. Parallel Comput.},
	author = {Maier, Tobias and Sanders, Peter and Dementiev, Roman},
	date = {2019},
	note = {Place: New York, {NY}, {USA}
Publisher: Association for Computing Machinery},
	keywords = {Concurrency, dynamic data structures, experimental analysis, hash table, lock-freedom, transactional memory, notion},
	file = {Maier et al. - 2019 - Concurrent Hash Tables Fast and General()!.pdf:/home/skadic/Zotero/storage/PKCNYSM3/Maier et al. - 2019 - Concurrent Hash Tables Fast and General()!.pdf:application/pdf},
}

@inproceedings{kurpicz_engineering_2022,
	title = {Engineering Compact Data Structures for Rank and Select Queries on Bit Vectors},
	volume = {13617},
	doi = {10.1007/978-3-031-20643-6_19},
	series = {Lecture Notes in Computer Science},
	pages = {257--272},
	booktitle = {{SPIRE}},
	publisher = {Springer},
	author = {Kurpicz, Florian},
	date = {2022},
	keywords = {notion},
	file = {Kurpicz - 2022 - Engineering Compact Data Structures for Rank and S.pdf:/home/skadic/Zotero/storage/GVADWWGQ/Kurpicz - 2022 - Engineering Compact Data Structures for Rank and S.pdf:application/pdf},
}
